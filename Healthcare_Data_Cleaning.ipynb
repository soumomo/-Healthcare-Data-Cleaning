# -*- coding: utf-8 -*-
"""Healthcare_Data_Cleaning.ipynb

# **Healthcare Data Cleaning**

## AI Mid-Semester Examination (MSE)
**Name:** [My Name]  
**Roll No:** [My Roll No]  
**Subject:** [Subject Name]
"""

# Import necessary libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from google.colab import files
import io
from scipy import stats

# Enable all warnings
import warnings
warnings.filterwarnings('always')

# Set plot styling
plt.style.use('ggplot')
sns.set(style="whitegrid")

# Create a section header function for better notebook organization
def section_header(title):
  """Display a formatted section header"""
  print(f"\n{'='*80}\n{title.upper()}\n{'='*80}\n")

"""## 1. Upload and Explore the Dataset"""

section_header("1. Upload and Explore the Dataset")

# Upload the file from user's computer
print("Please upload the healthcare_data.csv file:")
uploaded = files.upload()

# Read the uploaded file
file_name = next(iter(uploaded))
healthcare_df = pd.read_csv(io.BytesIO(uploaded[file_name]))

# Display basic information about the dataset
section_header("Basic Dataset Information")
print(f"Dataset shape: {healthcare_df.shape}")
print(f"\nFirst 5 rows of the dataset:")
display(healthcare_df.head())

print(f"\nDataset info:")
display(healthcare_df.info())

print(f"\nSummary statistics:")
display(healthcare_df.describe(include='all').T)

"""## 2. Data Quality Assessment"""

section_header("2. Data Quality Assessment")

# Check for missing values
print("Missing values per column:")
missing_values = healthcare_df.isnull().sum()
missing_pct = 100 * missing_values / len(healthcare_df)
missing_info = pd.DataFrame({
    'Missing Values': missing_values,
    'Percentage (%)': missing_pct.round(2)
})
display(missing_info[missing_info['Missing Values'] > 0])

# Visualize missing values
plt.figure(figsize=(12, 6))
sns.heatmap(healthcare_df.isnull(), cbar=False, cmap='viridis', yticklabels=False)
plt.title('Missing Values Heatmap')
plt.tight_layout()
plt.show()

# Check for duplicates
duplicate_count = healthcare_df.duplicated().sum()
print(f"\nNumber of duplicate rows: {duplicate_count}")
if duplicate_count > 0:
    print("First few duplicate rows:")
    display(healthcare_df[healthcare_df.duplicated(keep='first')])

# Check for inconsistencies in categorical columns
categorical_columns = healthcare_df.select_dtypes(include=['object']).columns
print("\nUnique values in categorical columns:")
for col in categorical_columns:
    unique_values = healthcare_df[col].unique()
    if len(unique_values) < 20:  # Only show if there aren't too many unique values
        print(f"\n{col}: {healthcare_df[col].unique()}")

# Check for potential outliers in numerical columns
numerical_cols = healthcare_df.select_dtypes(include=['int64', 'float64']).columns

fig, axes = plt.subplots(len(numerical_cols), 1, figsize=(12, 4*len(numerical_cols)))
if len(numerical_cols) == 1:
    axes = [axes]  # Make it iterable if there's only one numerical column

for i, col in enumerate(numerical_cols):
    if healthcare_df[col].nunique() > 1:  # Only plot if there's more than one unique value
        sns.boxplot(x=healthcare_df[col], ax=axes[i])
        axes[i].set_title(f'Boxplot of {col}')
        axes[i].set_xlabel(col)

plt.tight_layout()
plt.show()

"""## 3. Data Cleaning"""

section_header("3. Data Cleaning")

# Make a copy of the original data for comparison
healthcare_df_original = healthcare_df.copy()
healthcare_df_clean = healthcare_df.copy()

# 3.1 Handling missing values
print("3.1 HANDLING MISSING VALUES\n")

# Define a function to handle missing values based on data type
def handle_missing_values(df):
    """
    Handle missing values based on column data type and nature
    - Numerical: Impute with median
    - Categorical: Impute with mode
    - Date: Impute with median date
    """
    df_cleaned = df.copy()
    
    # For each column with missing values
    for col in df.columns:
        missing_count = df[col].isnull().sum()
        
        if missing_count > 0:
            print(f"Handling missing values in '{col}'")
            
            # For numerical columns
            if pd.api.types.is_numeric_dtype(df[col]):
                # If missing values are less than 30% of the data, impute with median
                if missing_count < 0.3 * len(df):
                    median_value = df[col].median()
                    df_cleaned[col].fillna(median_value, inplace=True)
                    print(f"  - Imputed {missing_count} missing values with median: {median_value}")
                else:
                    # If too many missing values, drop the column
                    df_cleaned.drop(col, axis=1, inplace=True)
                    print(f"  - Dropped column due to excessive missing values ({missing_count} rows)")
            
            # For categorical columns
            elif df[col].dtype == 'object':
                # If missing values are less than 30% of the data, impute with mode
                if missing_count < 0.3 * len(df):
                    mode_value = df[col].mode()[0]
                    df_cleaned[col].fillna(mode_value, inplace=True)
                    print(f"  - Imputed {missing_count} missing values with mode: '{mode_value}'")
                else:
                    # Check if this might be a non-mandatory field where NaN is valid
                    if 'notes' in col.lower() or 'comment' in col.lower() or 'optional' in col.lower():
                        df_cleaned[col].fillna('Not Provided', inplace=True)
                        print(f"  - Imputed {missing_count} missing values with 'Not Provided' (optional field)")
                    else:
                        df_cleaned.drop(col, axis=1, inplace=True)
                        print(f"  - Dropped column due to excessive missing values ({missing_count} rows)")
    
    return df_cleaned

# Apply the function to handle missing values
healthcare_df_clean = handle_missing_values(healthcare_df_clean)

# Check if there are still any missing values
remaining_missing = healthcare_df_clean.isnull().sum().sum()
print(f"\nRemaining missing values after imputation: {remaining_missing}")

# 3.2 Removing duplicates
print("\n3.2 REMOVING DUPLICATES\n")

# Count duplicates
duplicates_count = healthcare_df_clean.duplicated().sum()
print(f"Found {duplicates_count} duplicate rows")

# Remove duplicates
if duplicates_count > 0:
    healthcare_df_clean.drop_duplicates(inplace=True, keep='first')
    print(f"Removed {duplicates_count} duplicate rows")
    print(f"Dataset shape after removing duplicates: {healthcare_df_clean.shape}")

# 3.3 Handling outliers
print("\n3.3 HANDLING OUTLIERS\n")

# Define outlier detection and handling function
def handle_outliers(df, method='iqr', threshold=1.5):
    """
    Detect and handle outliers in numerical columns
    - method: 'iqr' (default) or 'zscore'
    - threshold: 1.5 (default for IQR) or 3 (common for z-score)
    """
    df_cleaned = df.copy()
    numerical_cols = df.select_dtypes(include=['int64', 'float64']).columns
    
    for col in numerical_cols:
        # Skip columns that should naturally have large ranges
        if 'id' in col.lower() or 'code' in col.lower():
            print(f"Skipping outlier detection for '{col}' as it appears to be an ID/code field")
            continue
            
        print(f"Checking for outliers in '{col}'")
        
        if method == 'iqr':
            # IQR method
            Q1 = df[col].quantile(0.25)
            Q3 = df[col].quantile(0.75)
            IQR = Q3 - Q1
            lower_bound = Q1 - threshold * IQR
            upper_bound = Q3 + threshold * IQR
            
            # Count outliers
            outliers = df_cleaned[(df_cleaned[col] < lower_bound) | 
                                 (df_cleaned[col] > upper_bound)]
            outlier_count = len(outliers)
            
            if outlier_count > 0:
                print(f"  - Detected {outlier_count} outliers using IQR method")
                print(f"  - Range: [{lower_bound}, {upper_bound}]")
                
                # Cap outliers to the boundaries instead of removing them
                df_cleaned.loc[df_cleaned[col] < lower_bound, col] = lower_bound
                df_cleaned.loc[df_cleaned[col] > upper_bound, col] = upper_bound
                print(f"  - Capped {outlier_count} outliers to the IQR boundaries")
        
        elif method == 'zscore':
            # Z-score method
            z_scores = stats.zscore(df[col].dropna())
            abs_z_scores = abs(z_scores)
            outlier_indices = abs_z_scores > threshold
            outlier_count = outlier_indices.sum()
            
            if outlier_count > 0:
                print(f"  - Detected {outlier_count} outliers using Z-score method")
                
                # Get the indices from the original dataframe that correspond to outliers
                filtered_indices = df[col].dropna().index[outlier_indices]
                
                # Cap outliers to the threshold z-score value in the direction of the outlier
                mean_val = df[col].mean()
                std_val = df[col].std()
                
                for idx in filtered_indices:
                    if df_cleaned.loc[idx, col] > mean_val:
                        df_cleaned.loc[idx, col] = mean_val + threshold * std_val
                    else:
                        df_cleaned.loc[idx, col] = mean_val - threshold * std_val
                
                print(f"  - Capped {outlier_count} outliers based on Z-score threshold")
    
    return df_cleaned

# Apply outlier handling
healthcare_df_clean = handle_outliers(healthcare_df_clean, method='iqr', threshold=1.5)

# 3.4 Fixing inconsistencies
print("\n3.4 FIXING INCONSISTENCIES\n")

def standardize_categorical_data(df):
    """Standardize categorical variables to consistent formats"""
    df_cleaned = df.copy()
    categorical_cols = df.select_dtypes(include=['object']).columns
    
    for col in categorical_cols:
        print(f"Checking inconsistencies in '{col}'")
        
        # Standardize common fields
        if 'gender' in col.lower() or 'sex' in col.lower():
            # Convert to lowercase first
            df_cleaned[col] = df_cleaned[col].str.lower()
            
            # Standardize gender values
            gender_mapping = {
                'm': 'Male', 'male': 'Male', 'man': 'Male', '1': 'Male', 'boy': 'Male',
                'f': 'Female', 'female': 'Female', 'woman': 'Female', '0': 'Female', 'girl': 'Female',
            }
            
            # Apply mapping only for values in the dictionary
            before_count = df_cleaned[col].nunique()
            df_cleaned[col] = df_cleaned[col].map(lambda x: gender_mapping.get(x, x))
            after_count = df_cleaned[col].nunique()
            
            print(f"  - Standardized gender values: {before_count} unique values → {after_count} unique values")
            print(f"  - Unique values after standardization: {df_cleaned[col].unique()}")
            
        elif 'blood' in col.lower() and 'type' in col.lower():
            # Standardize blood type values
            df_cleaned[col] = df_cleaned[col].str.upper().str.strip()
            
            # Fix common issues
            df_cleaned[col] = df_cleaned[col].str.replace(' ', '')
            df_cleaned[col] = df_cleaned[col].map({
                'A+': 'A+', 'APOSITIVE': 'A+', 'A-': 'A-', 'ANEGATIVE': 'A-',
                'B+': 'B+', 'BPOSITIVE': 'B+', 'B-': 'B-', 'BNEGATIVE': 'B-',
                'AB+': 'AB+', 'ABPOSITIVE': 'AB+', 'AB-': 'AB-', 'ABNEGATIVE': 'AB-',
                'O+': 'O+', 'OPOSITIVE': 'O+', 'O-': 'O-', 'ONEGATIVE': 'O-'
            }).fillna(df_cleaned[col])
            
            print(f"  - Standardized blood type values")
            print(f"  - Unique values after standardization: {df_cleaned[col].unique()}")
            
        elif 'name' in col.lower() or 'patient' in col.lower():
            # Format names properly (Title case)
            if df_cleaned[col].dtype == 'object':  # Only if it's a string column
                df_cleaned[col] = df_cleaned[col].str.title()
                print(f"  - Standardized name formats to title case")
                
        # Strip whitespace from string columns
        if df_cleaned[col].dtype == 'object':
            df_cleaned[col] = df_cleaned[col].str.strip()
            
    return df_cleaned

# Apply standardization
healthcare_df_clean = standardize_categorical_data(healthcare_df_clean)

# 3.5 Converting data types as needed
print("\n3.5 CONVERTING DATA TYPES\n")

def convert_data_types(df):
    """Convert columns to appropriate data types"""
    df_cleaned = df.copy()
    
    # Identify date columns (by name)
    potential_date_cols = [col for col in df.columns if 'date' in col.lower() or 
                           'admission' in col.lower() or 'discharge' in col.lower()]
    
    for col in potential_date_cols:
        # Try to convert to datetime
        try:
            df_cleaned[col] = pd.to_datetime(df_cleaned[col])
            print(f"Converted '{col}' to datetime")
        except:
            print(f"Could not convert '{col}' to datetime - keeping original type")
    
    # Ensure ID columns are strings (not numbers)
    id_columns = [col for col in df.columns if ('id' in col.lower() and 'id' == col.lower()[-2:]) or 
                  'code' in col.lower()]
    
    for col in id_columns:
        if df[col].dtype != 'object':
            df_cleaned[col] = df_cleaned[col].astype(str)
            print(f"Converted '{col}' to string")
    
    return df_cleaned

# Apply data type conversion
healthcare_df_clean = convert_data_types(healthcare_df_clean)

# 3.6 Additional data validation checks
print("\n3.6 ADDITIONAL DATA VALIDATION\n")

# Check for reasonable age values (if age column exists)
if 'age' in healthcare_df_clean.columns:
    invalid_ages = ((healthcare_df_clean['age'] < 0) | (healthcare_df_clean['age'] > 120)).sum()
    if invalid_ages > 0:
        print(f"Found {invalid_ages} rows with invalid ages (outside 0-120 range)")
        healthcare_df_clean = healthcare_df_clean[(healthcare_df_clean['age'] >= 0) & 
                                                 (healthcare_df_clean['age'] <= 120)]
        print(f"Removed {invalid_ages} rows with invalid ages")

# Check for other logical constraints in healthcare data
# Example: Check if discharge date is after admission date (if both columns exist)
date_cols = healthcare_df_clean.select_dtypes(include=['datetime64']).columns
admission_col = next((col for col in date_cols if 'admission' in col.lower()), None)
discharge_col = next((col for col in date_cols if 'discharge' in col.lower()), None)

if admission_col and discharge_col:
    invalid_dates = (healthcare_df_clean[discharge_col] < healthcare_df_clean[admission_col]).sum()
    if invalid_dates > 0:
        print(f"Found {invalid_dates} rows where discharge date is before admission date")
        # Swap incorrect dates
        idx = healthcare_df_clean[discharge_col] < healthcare_df_clean[admission_col]
        healthcare_df_clean.loc[idx, [admission_col, discharge_col]] = healthcare_df_clean.loc[idx, [discharge_col, admission_col]].values
        print(f"Fixed date inconsistencies by swapping values")

"""## 4. Data Analysis After Cleaning"""

section_header("4. Data Analysis After Cleaning")

# Compare original vs cleaned dataset
print(f"Original dataset shape: {healthcare_df_original.shape}")
print(f"Cleaned dataset shape: {healthcare_df_clean.shape}")
print(f"Difference in rows: {healthcare_df_original.shape[0] - healthcare_df_clean.shape[0]}")
print(f"Difference in columns: {healthcare_df_original.shape[1] - healthcare_df_clean.shape[1]}")

# Display summary statistics after cleaning
print("\nSummary statistics after cleaning:")
display(healthcare_df_clean.describe(include='all').T)

# Check if there are still missing values
print("\nMissing values after cleaning:")
display(healthcare_df_clean.isnull().sum())

# Visualize numerical distributions after cleaning
numerical_cols = healthcare_df_clean.select_dtypes(include=['int64', 'float64']).columns

if len(numerical_cols) > 0:
    plt.figure(figsize=(15, 10))
    for i, col in enumerate(numerical_cols[:min(len(numerical_cols), 9)]):  # Plot up to 9 columns
        plt.subplot(3, 3, i+1)
        sns.histplot(healthcare_df_clean[col], kde=True)
        plt.title(f'Distribution of {col}')
        plt.tight_layout()
    plt.show()

# Visualize categorical distributions after cleaning
categorical_cols = healthcare_df_clean.select_dtypes(include=['object']).columns

if len(categorical_cols) > 0:
    for col in categorical_cols:
        if healthcare_df_clean[col].nunique() < 10:  # Only plot if there aren't too many categories
            plt.figure(figsize=(10, 6))
            sns.countplot(y=healthcare_df_clean[col], order=healthcare_df_clean[col].value_counts().index)
            plt.title(f'Distribution of {col}')
            plt.tight_layout()
            plt.show()

"""## 5. Save Cleaned Data"""

section_header("5. Save Cleaned Data")

# Save the cleaned data to a new CSV file
healthcare_df_clean.to_csv('healthcare_data_cleaned.csv', index=False)
print("Saved cleaned data to 'healthcare_data_cleaned.csv'")

# Download the cleaned data
files.download('healthcare_data_cleaned.csv')
print("Downloaded cleaned data file")

"""## 6. Cleaning Summary"""

section_header("6. Cleaning Summary")

# Create a summary of the cleaning process
print("DATA CLEANING SUMMARY\n")
print(f"1. Initial Dataset: {healthcare_df_original.shape[0]} rows, {healthcare_df_original.shape[1]} columns")

# Count missing values in original dataset
original_missing = healthcare_df_original.isnull().sum().sum()
print(f"2. Missing Values: {original_missing} values imputed or columns dropped")

# Count duplicates in original dataset
original_duplicates = healthcare_df_original.duplicated().sum()
print(f"3. Duplicates: {original_duplicates} duplicate rows removed")

# Count outliers (this is approximate based on the previous outlier handling)
print(f"4. Outliers: Detected and capped in numerical columns using IQR method")

# Count standardized categories
print(f"5. Standardization: Standardized categorical columns including gender, blood type, etc.")

# Final dataset size
print(f"6. Final Dataset: {healthcare_df_clean.shape[0]} rows, {healthcare_df_clean.shape[1]} columns")

print("\nCOMPLETION METRICS:")
print(f"- Rows Processed: {healthcare_df_original.shape[0]}")
print(f"- Rows in Final Dataset: {healthcare_df_clean.shape[0]}")
print(f"- Data Reduction: {100 - (healthcare_df_clean.shape[0] / healthcare_df_original.shape[0] * 100):.2f}% rows")
print(f"- Missing Values Before: {original_missing}")
print(f"- Missing Values After: {healthcare_df_clean.isnull().sum().sum()}")
print(f"- Cleaning Success Rate: {100 * (1 - healthcare_df_clean.isnull().sum().sum() / (original_missing if original_missing > 0 else 1)):.2f}%")